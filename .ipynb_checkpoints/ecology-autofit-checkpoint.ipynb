{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import resource\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (1000,-1)) #allow many plots\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "rez=600 #pdf resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#upload and process the data\n",
    "thor = pd.read_excel('data/HIV_Integration_Sites_TableS3__corrected_15apr15.xlsx')\n",
    "thor = thor.dropna() #drop nan row\n",
    "mald = pd.read_csv('data/pmid24968937_maldarelli.tsv', sep='\\t')\n",
    "\n",
    "#rename because counts is taken in pandas\n",
    "new_columns = mald.columns.values; \n",
    "new_columns[5] = 'site_counts';\n",
    "mald.columns = new_columns \n",
    "\n",
    "for i in range(len(mald)):\n",
    "    if mald.inserted_gene[i] == 'not found':\n",
    "        mald.inserted_gene[i]=mald.nearest_gene[i] #fill in not founds with nearest\n",
    "    if len(mald.origin_id[i])<11:\n",
    "        mald.origin_id[i]=mald.origin_id[i][0:7]+'0'+mald.origin_id[i][7:] #add zeros to help sorting later\n",
    "    mald.origin_id[i].strip() #remove leading spaces\n",
    "\n",
    "\n",
    "thor_combine=True\n",
    "#fill in average time points for thor's data\n",
    "if thor_combine==True:\n",
    "    for i in range(len(thor)):\n",
    "        TP = thor['SAMPLING TIME INTERVAL \\n(YEARS ON ART)'][i]\n",
    "        if TP == 6.3 or TP == 7.1:\n",
    "            thor['SAMPLING TIME INTERVAL \\n(YEARS ON ART)'][i] = 6.8\n",
    "        if TP == 11.3 or TP == 12.7:\n",
    "            thor['SAMPLING TIME INTERVAL \\n(YEARS ON ART)'][i] = 12\n",
    "        if TP == 1.0 or TP == 1.3:\n",
    "            thor['SAMPLING TIME INTERVAL \\n(YEARS ON ART)'][i] = 1.1\n",
    "\n",
    "\n",
    "#participants\n",
    "thor_ppts = thor['PARTICIPANT'].unique()\n",
    "mald_tpts = mald['origin_id'].unique()\n",
    "\n",
    "mald_tpts.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the class for ecological analysis of integration sites\n",
    "class site_set:\n",
    "\n",
    "    def __init__(self, name, time, data, color, marker, participant):\n",
    "        self.name = name\n",
    "        self.t = time\n",
    "        self.data = data    \n",
    "        self.c = color\n",
    "        self.m = marker\n",
    "        self.ppt = participant\n",
    "            \n",
    "        #uses the raw data to make probability distributions and rank abundances\n",
    "        def analyze_counts(self):\n",
    "            counts=[]\n",
    "            d=self.data\n",
    "            #loop over all unique sites, make sure to account for 'X' as in Thor's data\n",
    "            for s in set(d):\n",
    "                if s!='X':\n",
    "                    counts.append(d.count(s))\n",
    "                else:\n",
    "                    for i in range(d.count('X')):\n",
    "                        counts.append(1)\n",
    "            self.N=len(d)#the total number of cells\n",
    "            self.abundance=-np.sort(-np.array(counts)) #put it as rank abundance   \n",
    "            self.Nx = np.bincount(counts) #the histogrammed data\n",
    "            self.px = self.Nx/sum(self.Nx) #make it a probability\n",
    "            self.Robs=len(self.abundance) #the observed richness\n",
    "            \n",
    "        #does the richness inference frmo Chao and jacknifes and the entropy!\n",
    "        def non_parametric_inference(self):\n",
    "            f1=self.Nx[1] #number singleton\n",
    "            #condition on f2>0\n",
    "            if self.Nx[2]>0:\n",
    "                f2=self.Nx[2] #fraction doubleton\n",
    "                self.Rchao = np.round(self.Robs + f1*(f1-1)/(2*(f2+1)))\n",
    "                rf=(f1/f2)\n",
    "                varR = f2*(rf**4/4 + rf**3 + rf**2/2)\n",
    "            else:\n",
    "                self.Rchao = self.Robs\n",
    "                varR=self.Robs\n",
    "                \n",
    "            #self.CI=np.exp(1.96*np.sqrt(np.log(1+varR/(self.Rchao-self.Robs)**2))) #the 95% confidence interval\n",
    "            self.CI=np.round(np.sqrt(varR)*2) #2 standard deviations\n",
    "\n",
    "            #jacknife estimators\n",
    "            self.Rj1=np.round(self.Robs+(self.N-1)/self.N*f1)\n",
    "            self.Rj2=np.round(self.Robs+(2*self.N-3)/self.N*self.Nx[1]-(self.N-2)**2*self.Nx[2]/(self.N*(self.N-1)))\n",
    "\n",
    "            #calculate Shannon entropy from coverage estimator\n",
    "            C_hat = 1 - f1/self.N\n",
    "            pi_n=C_hat*self.px\n",
    "            \n",
    "            self.S= -np.nansum(pi_n*np.log(pi_n)/(1-(1-pi_n)**self.N))\n",
    "\n",
    "        #run methods\n",
    "        analyze_counts(self)\n",
    "        non_parametric_inference(self)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make objects for the Thor data\n",
    "obz=[]\n",
    "\n",
    "markerz=['o','s','v', '>', '<']\n",
    "\n",
    "#make lists of colors for each patient?\n",
    "cz=[['lightcoral','maroon','red','indianred','brown',], #B\n",
    "    ['darkorange','burlywood','y','tan'], #L\n",
    "    ['navy','royalblue','mediumorchid'], #R\n",
    "    'lightgreen','darkgreen','green', #M1\n",
    "    'gray', #M2\n",
    "    'aqua','teal', #M3\n",
    "    'purple', #M4\n",
    "    'pink'] #M5 \n",
    "\n",
    "cz_ppts=['red','orange','navy','green','gray','blue','purple','pink']\n",
    "\n",
    "for i in range(len(thor_ppts)):\n",
    "    ppt=thor[thor['PARTICIPANT']==thor_ppts[i]]\n",
    "    thor_tpts = ppt['SAMPLING TIME INTERVAL \\n(YEARS ON ART)'].unique()\n",
    "    print(thor_tpts)\n",
    "    for j in range(len(thor_tpts)):\n",
    "        thor_data = ppt[ppt['SAMPLING TIME INTERVAL \\n(YEARS ON ART)']==thor_tpts[j]]\n",
    "        d=thor_data['GENE SYMBOL\\n(X=not annotated)'].tolist()\n",
    "\n",
    "        name_str='W_'+ppt['PARTICIPANT'].iloc[0][0]+'_'+str(thor_tpts[j]) #get the name as a string\n",
    "        \n",
    "        ob=site_set(name_str,thor_tpts[j],d,cz[i][j],markerz[j],ppt['PARTICIPANT'].iloc[0][0]) #define the object\n",
    "                \n",
    "        #add to big list of objects\n",
    "        obz.append(ob)\n",
    "\n",
    "#make objects for the Maldarelli data\n",
    "cz_ind=3\n",
    "for ppt in mald_tpts:\n",
    "    d=[]\n",
    "    sites=mald.inserted_gene[mald.origin_id==ppt] #get all sites from that participant    \n",
    "    u_sites=sites.unique() #find the unique sites\n",
    "        \n",
    "    #loop through all unique sites and add them several times\n",
    "    for s in u_sites:\n",
    "        for c in range(np.sum(mald.site_counts.iloc[u_sites==s])): #some sites found several times\n",
    "            d.append(s)\n",
    "        \n",
    "    name_str='M_'+ppt[4]+'_'+ppt[7:]\n",
    "    \n",
    "    ob=site_set(name_str,float(ppt[7:]),d,cz[cz_ind],markerz[(cz_ind-3)%3],ppt[4])\n",
    "\n",
    "    obz.append(ob)\n",
    "    cz_ind+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count distribution plots for each ppt\n",
    "fig,axarr=plt.subplots(2,4,sharex=True,sharey=True,dpi=600,figsize=(7,3))\n",
    "name='+'\n",
    "ppt_ind=-1\n",
    "for i in range(len(obz)):\n",
    "\n",
    "    if obz[i].name[2]!=name:\n",
    "        pl_t=[[],[]]\n",
    "        ppt_ind+=1\n",
    "        name=obz[i].name[2]\n",
    "        \n",
    "    ax=axarr[int(ppt_ind/4)][ppt_ind%4]\n",
    "    \n",
    "    Nx=obz[i].Nx\n",
    "\n",
    "    ss=ax.scatter(range(1,len(Nx)),Nx[1:],color=obz[i].c,marker=obz[i].m,s=15,alpha=0.8)\n",
    "    pl_t[0].append(ss)\n",
    "    pl_t[1].append(obz[i].t)\n",
    "    \n",
    "    ax.loglog()\n",
    "    ax.set_title(obz[i].name[:3],fontsize=8)\n",
    "    ax.legend(pl_t[0],pl_t[1],fontsize=8,loc=1)\n",
    "\n",
    "ax.set_xlim([0.5,1e2])\n",
    "ax.set_ylim([0.5,1e3])\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/obs_N-n.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print some sentences about the data\n",
    "num_clones=[]\n",
    "frac_clones=[]\n",
    "frac_cells_in_clones=[]\n",
    "cells_in_clones=[]\n",
    "cells_in_max_clone=[]\n",
    "frac_in_max_clone=[]\n",
    "for i in range(len(obz)):\n",
    "    ob=obz[i]\n",
    "    num_clones.append(sum(obz[i].Nx[2:]))\n",
    "    frac_clones.append(sum(obz[i].Nx[2:])/sum(obz[i].Nx))\n",
    "    \n",
    "    NS=obz[i].Nx*np.arange(len(obz[i].Nx)) #number of cells N(n)*n\n",
    "    cells_in_clones.append(sum(NS[2:])) #observed sequence clones\n",
    "    frac_cells_in_clones.append(sum(NS[2:])/obz[i].N) #observed sequence clones\n",
    "    cells_in_max_clone.append(NS[-1])\n",
    "    frac_in_max_clone.append(NS[-1]/ob.N)\n",
    "    \n",
    "def printer(x):\n",
    "    print(np.min(x),'-',np.max(x),'mean: ', np.mean(x))\n",
    "    \n",
    "print('number of observed sequences that were clonal')\n",
    "printer(num_clones)\n",
    "print('fraction of observed sequences that were clonal')\n",
    "printer(frac_clones)\n",
    "print('number of cells observed from clonal populations')\n",
    "printer(cells_in_clones)\n",
    "print('fraction of cells observed from clonal populations')\n",
    "printer(frac_cells_in_clones)\n",
    "print('number of cells observed in the largest clone')\n",
    "printer(cells_in_max_clone)\n",
    "print('fraction of cells observed in the largest clone')\n",
    "printer(frac_in_max_clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot “HIV sequence sample size (N)” (x-axis) versus “Number of distinct sequences (N(1)+2N(2)+3n(3)+….) (y-axis)\n",
    "\n",
    "#samples plotted out, most have <50\n",
    "plt.figure(figsize=(3,3),dpi=600)\n",
    "xtz=[]\n",
    "for i in range(len(obz)):\n",
    "    plt.scatter(obz[i].N,obz[i].Robs,color=obz[i].c,marker=obz[i].m,s=30,alpha=0.8)\n",
    "    xtz.append(obz[i].name)\n",
    "\n",
    "plt.loglog(np.arange(1e4),np.arange(1e4),ls='--',color='k',lw=1)\n",
    "plt.xlabel('sequence sample size, N')\n",
    "plt.ylabel('observed sequence \\n richness, $R^{obs}$')\n",
    "#plt.yticks(range(len(obz)),xtz,rotation=0,fontsize=10)\n",
    "plt.ylim([10,2e3])\n",
    "plt.xlim([10,2e3])\n",
    "#plt.ylim([-1,len(obz)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/obs_NvsR.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data fraction singleton\n",
    "plt.figure(figsize=(3,3),dpi=600)\n",
    "\n",
    "pltz=[[],[]]\n",
    "name='+'\n",
    "ppt_ind=-1\n",
    "for i in range(len(obz)):\n",
    "\n",
    "    if obz[i].name[2]!=name:\n",
    "        ppt_t=[]\n",
    "        ppt_RN=[]\n",
    "        name=obz[i].name[2]\n",
    "        ppt_ind+=1\n",
    "\n",
    "    ppt_t.append(obz[i].t)\n",
    "    sf=obz[i].Nx[1]/obz[i].N\n",
    "    ppt_RN.append(sf)\n",
    "\n",
    "    plt.scatter(obz[i].t,sf,color=obz[i].c,marker=obz[i].m,s=30,alpha=0.8)\n",
    "    lp=plt.plot(ppt_t,ppt_RN,color=cz_ppts[ppt_ind],lw=1,ls='-')\n",
    "\n",
    "    #pltz[0].append(lp)\n",
    "    #pltz[1].append(obz[i].name[:3])\n",
    "    \n",
    "#plt.legend(pltz[1])\n",
    "plt.xticks(range(0,16,2))\n",
    "plt.xlim([-1,16])\n",
    "plt.ylabel('observed singleton \\n fraction, $N(1)/N$')\n",
    "plt.xlabel('time on ART (years)')\n",
    "plt.ylim([0.5,1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/obs_sf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot richness and estimates\n",
    "t_all=np.array([obz[i].t for i in range(len(obz))])\n",
    "N_all=np.array([obz[i].N for i in range(len(obz))])\n",
    "datapoints_all=np.array([sum(obz[i].Nx>0) for i in range(len(obz))])\n",
    "\n",
    "#observed\n",
    "Ro_all=[obz[i].Robs for i in range(len(obz))]\n",
    "LRo=st.linregress(t_all,np.log10(Ro_all))\n",
    "\n",
    "#estimated Chao\n",
    "Rc_all=[obz[i].Rchao for i in range(len(obz))]\n",
    "LRc=st.linregress(t_all,np.log10(Rc_all))\n",
    "\n",
    "#jacknife estimators (not used for now)\n",
    "Rj1_all=[obz[i].Rj1 for i in range(len(obz))]\n",
    "Rj2_all=[obz[i].Rj2 for i in range(len(obz))]\n",
    "LRj1=st.linregress(t_all,np.log10(Rj1_all))\n",
    "LRj2=st.linregress(t_all,np.log10(Rj2_all))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,3),dpi=rez)\n",
    "\n",
    "name='+'\n",
    "ppt_ind=-1\n",
    "for i in range(len(obz)):\n",
    "\n",
    "    if obz[i].name[2]!=name:\n",
    "        ppt_t=[]\n",
    "        ppt_Robs=[]\n",
    "        ppt_Rchao=[]\n",
    "        ppt_RCI=[]\n",
    "        ppt_Rj1=[]\n",
    "        ppt_Rj2=[]\n",
    "        name=obz[i].name[2]\n",
    "        ppt_ind+=1\n",
    "\n",
    "    ob=obz[i]\n",
    "    \n",
    "    ppt_t.append(ob.t)\n",
    "    ppt_Robs.append(ob.Robs)\n",
    "    ppt_Rchao.append(ob.Rchao)\n",
    "    ppt_RCI.append(ob.CI)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.scatter(ob.t,ob.Robs,color=ob.c,marker=ob.m,s=30,alpha=0.8)\n",
    "    plt.semilogy(ppt_t,ppt_Robs,color=cz_ppts[ppt_ind],lw=1,ls='-')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.scatter(ob.t,ob.Rchao,color=ob.c,marker=ob.m,s=30,alpha=0.8)\n",
    "    plt.errorbar(ppt_t,ppt_Rchao,yerr=(np.zeros(len(ppt_RCI)),ppt_RCI),color=cz_ppts[ppt_ind],lw=1,ls='-')\n",
    "    plt.yscale('log')\n",
    "\n",
    "tt=np.linspace(0,max(t_all),100) #time series for linear regression\n",
    "yo=10**(tt*LRo[0]+LRo[1])\n",
    "yc=10**(tt*LRc[0]+LRc[1])\n",
    "\n",
    "plt.subplot(121)\n",
    "#plt.semilogy(tt,yo,lw=5,ls='-',color='gray',alpha=0.3)\n",
    "plt.title(r'observed ($R^{obs}$)',fontsize=10)\n",
    "plt.ylabel('sequence richness,' + r' $R$') \n",
    "plt.xticks(range(0,16,2))\n",
    "plt.ylim([10,1e4])\n",
    "plt.xlabel('time on ART (years)')    \n",
    "\n",
    "plt.subplot(122)\n",
    "#plt.semilogy(tt,yc,lw=5,ls='-',color='gray',alpha=0.3)\n",
    "plt.title(r'estimated ($R^{Chao}$)',fontsize=10)\n",
    "plt.xlim([-1,16])\n",
    "plt.xticks(range(0,16,2))\n",
    "plt.ylim([10,1e4])\n",
    "plt.xlabel('time on ART (years)')    \n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figures/nonparametric_richness.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#helper normalizer for probability distributions\n",
    "def normalize(pxx):\n",
    "    return pxx/sum(pxx)\n",
    "\n",
    "#functions to auto-fit\n",
    "def fit_models(ob):\n",
    "\n",
    "    xd=np.arange(1,len(ob.Nx)) #xrange for data\n",
    "    d=ob.Nx[1:] #the count data\n",
    "    \n",
    "    #define each model, return negative log-likelihood, \n",
    "    #the number we want to minimize (to maximize the likelihood)\n",
    "    def autofit_pwl1(param):            \n",
    "        al=param\n",
    "        pxd=normalize(xd**(-al))\n",
    "        logL=np.sum(d*np.log(pxd))\n",
    "        return -logL\n",
    "\n",
    "    def autofit_pwl2(param):            \n",
    "        al1,al2,phi=param\n",
    "        #pxd=normalize(xex**(-al1)+phi*xex**(-al2))\n",
    "        pxd=normalize(xd**(-al1)+10**phi*xd**(-10**al2)) #exponential parameter values\n",
    "        logL=np.sum(d*np.log(pxd))        \n",
    "        return -logL\n",
    "\n",
    "    def autofit_ilog(param):            \n",
    "        w=1+10**param\n",
    "        #w=param\n",
    "        pxd=normalize(1/np.log(w*xd))\n",
    "        logL=np.sum(d*np.log(pxd))\n",
    "        return -logL\n",
    "\n",
    "    def autofit_gamm(param):            \n",
    "        al,lam=param\n",
    "        pxd=normalize(1/sp.special.gamma(al)*lam**al*xd**(al-1)*np.exp(-lam*xd))\n",
    "        logL=np.sum(d*np.log(pxd))\n",
    "        return -logL\n",
    "\n",
    "    #initial conditions for model fits\n",
    "    pwl1_0=(2)\n",
    "    pwl2_0=(4,-3,-2)\n",
    "    ilog_0=(-3)\n",
    "    #gamm_0=(1,1)\n",
    "\n",
    "    #fit each function (need to figuyre out bounds)\n",
    "    bf_pwl1=sp.optimize.minimize(autofit_pwl1,pwl1_0,method='Nelder-Mead') #best fit powerlaw 1\n",
    "    bf_pwl2=sp.optimize.minimize(autofit_pwl2,pwl2_0,method='Nelder-Mead') #best fit powerlaw biphasic\n",
    "\n",
    "    #bf_pwl1=sp.optimize.minimize(autofit_pwl1,pwl1_0,bounds=((0,10),),method='Levenberg-Marquardt') #best fit powerlaw 1\n",
    "    #bf_pwl2=sp.optimize.minimize(autofit_pwl2,pwl2_0,bounds=((0,10),(None,0),(None,0))) #best fit powerlaw biphasic\n",
    "    #bf_ilog=sp.optimize.minimize(autofit_ilog,ilog_0,bounds=((-5,0),)) #best fit inv-log\n",
    "    #bf_gamm=sp.optimize.minimize(autofit_gamm,gamm_0,bounds=((None,None),(None,None))) #best fit gamma function\n",
    "\n",
    "    return bf_pwl1,bf_pwl2#,bf_ilog,bf_gamm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions to auto-fit\n",
    "def fit_models_cdf(ob):\n",
    "\n",
    "    xd=np.arange(1,len(ob.Nx)) #xrange for data\n",
    "    d=np.cumsum(ob.px[1:]) #the count data\n",
    "    \n",
    "    #define each model, return negative log-likelihood, \n",
    "    #the number we want to minimize (to maximize the likelihood)\n",
    "    def autofit_pwl1(param):            \n",
    "        al=param\n",
    "        pxd=np.cumsum(normalize(xd**(-al)))\n",
    "        KS=max(np.abs(pxd-d))\n",
    "        return KS\n",
    "\n",
    "    def autofit_pwl2(param):            \n",
    "        al1,al2,phi=param\n",
    "        pxd=np.cumsum(normalize(xd**(-al1)+10**phi*xd**(-10**al2))) #exponential parameter values\n",
    "        KS=max(np.abs(pxd-d))\n",
    "        return KS\n",
    "\n",
    "    def autofit_ilog(param):            \n",
    "        w=1+10**param\n",
    "        pxd=normalize(1/np.log(w*xd))\n",
    "        KS=max(np.abs(pxd-d))\n",
    "        return KS\n",
    "\n",
    "    def autofit_gamm(param):            \n",
    "        al,lam=param\n",
    "        pxd=np.cumsum(normalize(1/sp.special.gamma(al)*lam**al*xd**(al-1)*np.exp(-lam*xd)))\n",
    "        logL=np.sum(d*np.log(pxd))\n",
    "        return -logL\n",
    "\n",
    "    #initial conditions for model fits\n",
    "    pwl1_0=(2)\n",
    "    pwl2_0=(4,-3,-2)\n",
    "    ilog_0=(-4)\n",
    "\n",
    "    #fit each function (need to figuyre out bounds)\n",
    "    bf_pwl1=sp.optimize.minimize(autofit_pwl1,pwl1_0,bounds=((0,None),)) #best fit powerlaw 1\n",
    "    bf_pwl2=sp.optimize.minimize(autofit_pwl2,pwl2_0,bounds=((0,None),(None,0),(None,0))) #best fit powerlaw biphasic\n",
    "\n",
    "    #bf_pwl1=sp.optimize.minimize(autofit_pwl1,pwl1_0,method='Nelder-Mead') #best fit powerlaw 1\n",
    "    #bf_pwl2=sp.optimize.minimize(autofit_pwl2,pwl2_0,method='Nelder-Mead') #best fit powerlaw biphasic\n",
    "    #bf_ilog=sp.optimize.minimize(autofit_ilog,ilog_0,bounds=((None,0),)) #best fit inv-log\n",
    "    #bf_gamm=sp.optimize.minimize(autofit_gamm,gamm_0,bounds=((None,None),(None,None))) #best fit gamma function\n",
    "\n",
    "    return bf_pwl1,bf_pwl2#,bf_ilog,bf_gamm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#supplementary figures, fit each participant separately for each model\n",
    "\n",
    "fig1,aa1=plt.subplots(3,6,sharex=True,sharey=True,dpi=600,figsize=(8,5))\n",
    "fig2,aa2=plt.subplots(3,6,sharex=True,sharey=True,dpi=600,figsize=(8,5))\n",
    "#fig3,aa3=plt.subplots(3,6,sharex=True,sharey=True,dpi=600,figsize=(8,5))\n",
    "#fig4,aa4=plt.subplots(3,6,sharex=True,sharey=True,dpi=600,figsize=(8,5))\n",
    "\n",
    "axz=[aa1,aa2]#,aa3,aa4]\n",
    "\n",
    "likelihood_comparison=np.zeros([len(axz),len(obz)]) #to compare likelihoods later\n",
    "\n",
    "bf_list=[]\n",
    "#loop over participant timepoints\n",
    "for i in range(len(obz)):\n",
    "    ob=obz[i] #the object\n",
    "    xd=range(1,len(ob.Nx)) #data range\n",
    "    #bf_models=fit_models(ob) #fit all models\n",
    "    bf_models=fit_models_cdf(ob) #fit all models\n",
    "    bf_list.append(bf_models)\n",
    "    #loop over models\n",
    "    for j in range(len(axz)):\n",
    "        ax=axz[j][int(i/6)][i%6]\n",
    "        ax.set_title(ob.name,fontsize=8)\n",
    "\n",
    "        #compute the models for the data range\n",
    "        if j==0:\n",
    "            al,=bf_models[0].x\n",
    "            pxd=normalize(xd**(-al))\n",
    "            #print(al)\n",
    "        if j==1:\n",
    "            al1=bf_models[1].x[0]\n",
    "            al2=bf_models[1].x[1]\n",
    "            phi=bf_models[1].x[2]\n",
    "            pxd=normalize(xd**(-al1)+10**phi*xd**(-10**al2))\n",
    "            #print(al1,10**al2,10**phi)\n",
    "        if j==2:\n",
    "            w,=1+10**bf_models[2].x\n",
    "            pxd=normalize(1./np.log(w*xd))\n",
    "            print(w)\n",
    "        if j==3:\n",
    "            al=bf_models[3].x[0]\n",
    "            lam=bf_models[3].x[1]\n",
    "            pxd=normalize(1/sp.special.gamma(al)*lam**al*xd**(al-1)*np.exp(-lam*xd))\n",
    "               \n",
    "        logL=np.sum(ob.Nx[1:]*np.log(pxd))\n",
    "        likelihood_comparison[j,i]=logL #add likelihood from best fit\n",
    "          \n",
    "        #plot the best fit models on each plot\n",
    "        ax.scatter(xd,ob.px[1:],color=ob.c,marker=ob.m,s=20)\n",
    "        ax.loglog(xd,pxd,color=ob.c,lw=3,alpha=0.7)\n",
    "        ax.set_xlim([0.8,1e2])\n",
    "        ax.set_ylim([1e-5,2])\n",
    "\n",
    "#remove last axis      \n",
    "for j in range(len(axz)):\n",
    "    axz[j][2][5].remove()\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig1.savefig('figures/best_fit-pwl1.pdf')\n",
    "\n",
    "fig2.tight_layout()\n",
    "fig2.savefig('figures/best_fit-pwl2.pdf')\n",
    "\n",
    "#fig3.tight_layout()\n",
    "#fig3.savefig('figures/best_fit-ilog.pdf')\n",
    "#fig4.tight_layout()\n",
    "#fig4.savefig('figures/best_fit-gamm.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compare model fits with likelihood\n",
    "fig,aa=plt.subplots(3,6,sharex=True,sharey=True,dpi=600,figsize=(8,5))\n",
    "\n",
    "mz=['s','d','o'] #leave out gamma\n",
    "modelz=['pwl1','pwl2','inv-log','gamma']\n",
    "\n",
    "#loop over participant timepoints\n",
    "for i in range(len(obz)):\n",
    "    ob=obz[i]\n",
    "    ax=aa[int(i/6)][i%6]\n",
    "    #loop over models\n",
    "    for j in range(len(axz)):\n",
    "        ax.scatter(j,likelihood_comparison[j,i]/ob.N,c=ob.c,marker=mz[j],s=30,lw=1) #scatter likelihoods to compare models\n",
    "    ax.set_title(ob.name,fontsize=8)\n",
    "    ax.grid()\n",
    "\n",
    "ax.set_xlim([-1,2])\n",
    "ax.set_xticks(range(len(mz)))\n",
    "ax.set_xticklabels([])\n",
    "ax.legend(modelz[:len(mz)],bbox_to_anchor=(1.1, 1), loc=2,fontsize=10)\n",
    "#for j in range(len(mz)):\n",
    "#    ax=aa[2][5]\n",
    "#    ax.scatter(j,10,c='k',marker=mz[j],s=30,lw=1) #scatter likelihoods to compare models\n",
    "#plt.legend(modelz[:len(mz)],fontsize=10)\n",
    "#ax.set_yticklabels([])\n",
    "#ax.set_ylim([0,1])\n",
    "aa[2][5].remove()\n",
    "aa[1][0].set_ylabel('adjusted \\n log-likelihood')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/likelihood_allcomps.pdf')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#correlate fits with sample size\n",
    "num_params=[1,3,1,3]\n",
    "\n",
    "#plot likelihood ratios\n",
    "plt.figure(figsize=(5,3),dpi=rez)\n",
    "\n",
    "#compute the information criteria\n",
    "IC=np.zeros([len(axz),len(obz)]) #to compare likelihoods later\n",
    "for i in range(len(axz)):\n",
    "    #IC[i,:]=2*num_params[i]-2*likelihood_comparison[i,:]; fn='AIC'; #AIC\n",
    "    IC[i,:]=np.log(datapoints_all)*num_params[i]-2*likelihood_comparison[i,:]; fn='BIC' #BIC\n",
    "\n",
    "#plot the delta IC, depending on the IC chosen\n",
    "for i in range(len(obz)):\n",
    "    plt.scatter(N_all[i],IC[0,i]-IC[1,i],marker=obz[i].m,color=obz[i].c,s=50,lw=1,alpha=0.8) #scatter likelihoods to compare models\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.ylabel('$\\Delta$'+fn+' (pwl2-pwl1)')\n",
    "plt.xlabel('sample size, $N$')\n",
    "plt.axhline(0,color='k',ls='--',lw=1)\n",
    "plt.xlim([30,1e3])\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/'+fn+'_comp.pdf')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compare model fits with AIC\n",
    "fig,aa=plt.subplots(3,6,sharex=True,sharey=False,dpi=600,figsize=(8,5))\n",
    "\n",
    "mz=['s','d','o'] #leave out gamma\n",
    "modelz=['pwl1','pwl2','inv-log','gamma']\n",
    "num_params=[1,3,1,2] #for BIC\n",
    "\n",
    "#loop over participant timepoints\n",
    "for i in range(len(obz)):\n",
    "    ob=obz[i]\n",
    "    ax=aa[int(i/6)][i%6]\n",
    "    #loop over models\n",
    "    for j in range(len(axz)):\n",
    "        ax.scatter(j,IC[j,i],c=ob.c,marker=mz[j],s=30,lw=1) #scatter likelihoods to compare models\n",
    "    ax.set_title(ob.name,fontsize=8)\n",
    "    ax.grid()\n",
    "\n",
    "ax.set_xticks(range(len(axz)))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlim([-1,2])\n",
    "ax.legend(modelz[:len(axz)],bbox_to_anchor=(1.1, 1), loc=2,fontsize=10)\n",
    "aa[2][5].remove()\n",
    "aa[1][0].set_ylabel(fn)\n",
    "plt.yscale('log')\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/'+fn+'_allcomps.pdf')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compare powerlaw model exponents\n",
    "jit=0.1 #jitter factor\n",
    "plt.figure(figsize=(4,3),dpi=rez)\n",
    "al_list=[]; al1_list=[]; al2_list=[]\n",
    "for i in range(len(obz)):\n",
    "    ob=obz[i] #the object\n",
    "    bf_models=bf_list[i]\n",
    "    #loop over models\n",
    "    for j in range(len(axz)):\n",
    "        #compute the models for the data range\n",
    "        if j==0:\n",
    "            al_list.append(bf_models[0].x)\n",
    "            #plt.subplot(131)\n",
    "            plt.scatter(np.random.normal(1,jit),al_list[i],c=ob.c,marker=ob.m)\n",
    "            #plt.yscale('log')\n",
    "            #plt.xticks([1],[r'pwl1 ($\\alpha$)'])\n",
    "        if j==1:\n",
    "            al1_list.append(bf_models[1].x[0])\n",
    "            #plt.subplot(132)\n",
    "            plt.scatter(np.random.normal(2,jit),al1_list[i],c=ob.c,marker=ob.m)\n",
    "            #plt.xticks([2],[r'pwl2 ($\\alpha_1$)'])\n",
    "            #plt.yscale('log')\n",
    "            #plt.ylim([1e-4,3e1])\n",
    "            \n",
    "            al2_list.append(10**bf_models[1].x[1])\n",
    "            #plt.subplot(133)            \n",
    "            plt.scatter(np.random.normal(3,jit),al2_list[i],c=ob.c,marker=ob.m)\n",
    "            #plt.xticks([3],[r'pwl2 ($\\alpha_2$)'])\n",
    "            #plt.yscale('log')\n",
    "            #plt.ylim([1e-4,3e1])\n",
    "\n",
    "#plt.boxplot([al_list,al1_list,al2_list],positions=[1,2,3])\n",
    "plt.xticks([1,2,3],[r'pwl1 ($\\alpha$)',r'pwl2 ($\\alpha_1$)',r'pwl2 ($\\alpha_2$)'])\n",
    "plt.yscale('log')\n",
    "plt.ylim([1e-4,3e1])\n",
    "plt.xlabel('model (parameter)')\n",
    "plt.ylabel('value')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/model_parameters.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now extrapolate all models\n",
    "\n",
    "thL=-5.2e-4*365 #decay rate in years\n",
    "\n",
    "sf_ex=np.zeros([len(mz),len(obz)]) #singleton fraction\n",
    "R_ex=np.zeros([len(mz),len(obz)]) #extrapolated richness\n",
    "L_ex=np.zeros([len(mz),len(obz)]) #extrapolated reservoir size\n",
    "\n",
    "Nex_list=[[],[],[]]\n",
    "aex_list=[[],[],[]]\n",
    "rex_list=[[],[],[]]\n",
    "\n",
    "#loop over participant timepoints\n",
    "for i in range(len(obz)):\n",
    "    ob=obz[i] #the object\n",
    "    xd=range(1,len(ob.Nx)) #data range\n",
    "    bf_models=bf_list[i]\n",
    "    \n",
    "    L=1e9#1e6*np.exp(thL*ob.t)\n",
    "    maxx=int(np.sqrt(8*L)/2) #solving sum_1^n i = n(n+1)/2 = L\n",
    "    xex=np.arange(1,maxx+1) #extrapolated range (maximum possible if all had 1)\n",
    "    \n",
    "    #loop over models\n",
    "    for j in range(len(axz)):\n",
    "        #compute the models for the data range\n",
    "        if j==0:\n",
    "            al=bf_models[0].x\n",
    "            pxd=normalize(xex**(-al))\n",
    "        if j==1:\n",
    "            al1=bf_models[1].x[0]\n",
    "            al2=bf_models[1].x[1]\n",
    "            phi=bf_models[1].x[2]\n",
    "            #pxd=normalize(xex**(-al1)+phi*xex**(-al2))\n",
    "            pxd=normalize(xex**(-al1)+10**phi*xex**(-10**al2))\n",
    "        if j==2:\n",
    "            #w=bf_models[2].x\n",
    "            w=1+10**bf_models[2].x\n",
    "            pxd=normalize(1./np.log(w*xex))\n",
    "        if j==3:\n",
    "            al=bf_models[3].x[0]\n",
    "            lam=bf_models[3].x[1]\n",
    "            pxd=normalize(1/sp.special.gamma(al)*lam**al*xex**(al-1)*np.exp(-lam*xex))\n",
    "\n",
    "        #get the right reservoir volume (do it twice for rounding)\n",
    "        Ntot=np.sum(pxd*xex) #total number of cells in reservoir\n",
    "        C=L/Ntot #constant to make reservoir volume right\n",
    "        Nex=np.round(C*pxd)\n",
    "        Ntot=np.sum(Nex*xex) #check volume\n",
    "        \n",
    "        Nex_list[j].append(Nex)\n",
    "        \n",
    "        #rank abundance distributions\n",
    "        ab=[]\n",
    "        for jj in range(len(Nex)):\n",
    "            ab.append(list(np.ones(int(Nex[jj]))*(jj+1)))\n",
    "        abund=np.flipud(sum(ab, [])) #flatten the list\n",
    "        ranks=np.arange(1,len(abund)+1)\n",
    "                \n",
    "        aex_list[j].append(abund)\n",
    "        rex_list[j].append(np.arange(1,len(abund)+1))\n",
    "\n",
    "        sf_ex[j,i] = Nex[0]/Ntot\n",
    "        R_ex[j,i] = max(ranks[abund>0])\n",
    "        L_ex[j,i] = Ntot\n",
    "\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plots\n",
    "for j in range(len(axz)):\n",
    "    plt.figure(figsize=(7,3),dpi=rez)\n",
    "    for i in range(len(obz)):\n",
    "\n",
    "        ob=obz[i]\n",
    "        \n",
    "        #probability distributions\n",
    "        plt.subplot(121)\n",
    "        Nex=Nex_list[j][i]\n",
    "        xex=np.arange(1,len(Nex)+1)\n",
    "        plt.loglog(xex,Nex,color=ob.c)\n",
    "        #plt.title(modelz[j],fontsize=10)\n",
    "        plt.xlim([1,1e4])\n",
    "        plt.ylim([0.8,1e6])\n",
    "        plt.xticks(10**np.arange(5))\n",
    "        plt.yticks(10**np.arange(7))\n",
    "        plt.minorticks_off()\n",
    "        plt.xlabel('extrapolated clone size, $n^{ex}$')\n",
    "        plt.ylabel('extrapolated clone \\n size abundance, $N^{ex}$')\n",
    "\n",
    "        #rank abundance distributions\n",
    "        abund=aex_list[j][i]\n",
    "        ranks=rex_list[j][i]\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.loglog(ranks,abund,color=ob.c)\n",
    "        plt.ylim([0.8,1e4])\n",
    "        plt.xlim([1,1e6])\n",
    "        plt.xticks(10**np.arange(7))\n",
    "        plt.yticks(10**np.arange(5))\n",
    "        plt.minorticks_off()\n",
    "        plt.xlabel('extrapolated rank, $r^{ex}$')\n",
    "        plt.ylabel('extrapolated abundance, $a^{ex}$')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/ex_dists_'+modelz[j]+'.pdf')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions for sampling from distributions\n",
    "\n",
    "#sample from extrapolated count distribution\n",
    "def sample_px(xex,Nex,ns):\n",
    "    nz=0\n",
    "    sim_samples=[]\n",
    "    while nz<ns:\n",
    "        max_poss=ns-nz #max possible clone size based on samples remaining\n",
    "        custm = st.rv_discrete(name='custm', values=(xex[:max_poss], Nex[:max_poss]/sum(Nex[:max_poss])))\n",
    "        sampz=custm.rvs(size=1)\n",
    "        sim_samples.append(sampz[0])\n",
    "        nz+=sampz\n",
    "    #print(sim_samples)\n",
    "    Nsx=np.bincount(sim_samples)\n",
    "    return Nsx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#supplementary figures, plot sampled distributions against participant data separately for each model\n",
    "\n",
    "fig1,aa1=plt.subplots(3,6,sharex=True,sharey=True,dpi=600,figsize=(8,5))\n",
    "fig2,aa2=plt.subplots(3,6,sharex=True,sharey=True,dpi=600,figsize=(8,5))\n",
    "axz=[aa1,aa2]\n",
    "\n",
    "xsx=np.arange(1000) #maximum value for sampels\n",
    "\n",
    "num_replicates=10\n",
    "#lsz=['-','-.']\n",
    "#loop over participant timepoints\n",
    "for i in range(len(obz)):\n",
    "    ob=obz[i] #the object\n",
    "    xd=range(1,len(ob.Nx)) #data range\n",
    "    #loop over models\n",
    "    for j in range(len(axz)):\n",
    "        #ax=aa1[[int(i/6)][i%6]\n",
    "        ax=axz[j][int(i/6)][i%6]\n",
    "        ax.set_title(ob.name,fontsize=8)\n",
    "\n",
    "        abund=aex_list[j][i]\n",
    "        ranks=rex_list[j][i]\n",
    "        Nex=Nex_list[j][i]\n",
    "        xex=np.arange(1,len(Nex)+1)\n",
    "                \n",
    "        Nsx=np.zeros([num_replicates,1000])\n",
    "        for k in range(num_replicates):\n",
    "            spx=sample_px(xex,Nex,ob.N)\n",
    "            Nsx[k,:len(spx)]=spx\n",
    "            #sra=np.bincount(np.random.multinomial(ob.N,abund/sum(abund))) #try sampling from rank abundance\n",
    "            #Nsx[k,:len(sra)]=sra\n",
    "            ax.scatter(xsx[Nsx[k,:]>0],Nsx[k,Nsx[k,:]>0],color='k',marker='x',s=20)\n",
    "\n",
    "        \n",
    "        #plot the best fit models on each plot\n",
    "        ax.scatter(xd,ob.Nx[1:],color=ob.c,marker=ob.m,s=20,alpha=0.7)\n",
    "        \n",
    "        #or plot average from replicates\n",
    "        #if num_replicates>1:\n",
    "        #    avg_Nsx=np.mean(Nsx,0)\n",
    "        #else:\n",
    "        #    avg_Nsx=Nsx[0]\n",
    "        #ax.plot(xsx[avg_Nsx>0],avg_Nsx[avg_Nsx>0],color='k',ls=lsz[j])#,marker='x',s=20)\n",
    "        \n",
    "        ax.set_xlim([0.5,1e3])\n",
    "        ax.set_ylim([0.5,1e3])\n",
    "        #ax.set_ylim([0.5,100])\n",
    "\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "#remove last axis      \n",
    "for j in range(len(axz)):\n",
    "    axz[j][2][5].remove()\n",
    "fig1.tight_layout()\n",
    "fig1.savefig('figures/sample_bestfit-pwl1.pdf')\n",
    "\n",
    "fig2.tight_layout()\n",
    "fig2.savefig('figures/sample_bestfit-pwl2.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot extrapolated singletons\n",
    "for mo in range(len(axz)):\n",
    "    plt.figure(figsize=(3,3),dpi=rez)\n",
    "    name='+'\n",
    "    ppt_ind=-1\n",
    "    for i in range(len(obz)):\n",
    "\n",
    "        if obz[i].name[2]!=name:\n",
    "            ppt_obs=[]\n",
    "            ppt_t=[]\n",
    "            ppt_all=[]\n",
    "            ppt_ind+=1\n",
    "            name=obz[i].name[2]\n",
    "\n",
    "        sf=sf_ex[mo,i]\n",
    "        \n",
    "        ppt_t.append(obz[i].t)\n",
    "        ppt_all.append(sf)\n",
    "\n",
    "        plt.scatter(obz[i].t,sf,color=obz[i].c,s=30,marker=obz[i].m)\n",
    "        plt.plot(ppt_t,ppt_all,color=cz_ppts[ppt_ind],lw=1,ls='-')\n",
    "\n",
    "    #plt.title(modelz[mo],fontsize=10)\n",
    "    if mo>0:\n",
    "        plt.yscale('log')\n",
    "    plt.xlabel('time on ART (years)')    \n",
    "    plt.ylabel('extrapolated singleton \\n' + r'fraction, $N^{ex}(1)/N^{ex}$') \n",
    "    plt.xlim([-1,16])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/ex_sf_'+modelz[mo]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot extrapolated richness\n",
    "all_r=np.zeros([len(obz),len(axz)])\n",
    "for mo in range(len(axz)):\n",
    "    plt.figure(figsize=(3,3),dpi=rez)\n",
    "    name='+'\n",
    "    ppt_ind=-1\n",
    "    for i in range(len(obz)):\n",
    "\n",
    "        if obz[i].name[2]!=name:\n",
    "            ppt_obs=[]\n",
    "            ppt_t=[]\n",
    "            ppt_all=[]\n",
    "            ppt_ind+=1\n",
    "            name=obz[i].name[2]\n",
    "\n",
    "        r=R_ex[mo,i]\n",
    "        \n",
    "        all_r[i,mo]=np.log10(r)-np.log10(obz[i].Rchao)\n",
    "        \n",
    "        ppt_t.append(obz[i].t)\n",
    "        ppt_all.append(r)\n",
    "\n",
    "        plt.scatter(obz[i].t,r,color=obz[i].c,s=30,marker=obz[i].m)\n",
    "        plt.semilogy(ppt_t,ppt_all,color=cz_ppts[ppt_ind],lw=1,ls='-')\n",
    "\n",
    "    #plt.title(modelz[mo],fontsize=10)\n",
    "    plt.xlabel('time on ART (years)')    \n",
    "    plt.ylabel('extrapolated richness, $R^{ex}$') \n",
    "    plt.ylim([1,2e6])\n",
    "    plt.xlim([-1,16])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/ex_R'+modelz[mo]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3),dpi=rez)\n",
    "#plt.boxplot(all_r)\n",
    "for mo in range(len(axz)):\n",
    "    for i in range(len(obz)):\n",
    "        y = all_r[i,mo]\n",
    "        x = np.random.normal(mo+1, 0.02)\n",
    "        plt.scatter(x, y, marker=obz[i].m,color=obz[i].c, alpha=0.8)\n",
    "\n",
    "plt.axhline(0,color='k',ls='--',lw=1)\n",
    "plt.xlim([0.5,2.5])\n",
    "plt.xticks([1,2],modelz)\n",
    "plt.ylabel('log10 difference in richness \\n (model-Chao)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/richness_comp.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot extrapolated reservoir size\n",
    "for mo in range(len(axz)):\n",
    "    plt.figure(figsize=(3,3),dpi=rez)\n",
    "    name='+'\n",
    "    ppt_ind=-1\n",
    "    for i in range(len(obz)):\n",
    "\n",
    "        if obz[i].name[2]!=name:\n",
    "            ppt_obs=[]\n",
    "            ppt_t=[]\n",
    "            ppt_all=[]\n",
    "            ppt_ind+=1\n",
    "            name=obz[i].name[2]\n",
    "\n",
    "        l=L_ex[mo,i]\n",
    "        \n",
    "        ppt_t.append(obz[i].t)\n",
    "        ppt_all.append(l)\n",
    "\n",
    "        plt.scatter(obz[i].t,l,color=obz[i].c,s=30,marker=ob.m)\n",
    "        plt.semilogy(ppt_t,ppt_all,color=cz_ppts[ppt_ind],lw=1,ls='-')\n",
    "\n",
    "    #plt.title(modelz[mo],fontsize=10)\n",
    "    plt.xlabel('time on ART (years)')    \n",
    "    plt.ylabel('extrapolated reservoir \\n' + r'size, $N^{ex}$') \n",
    "    plt.xlim([-1,16])\n",
    "    plt.ylim([1e4,1e7])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/ex_L'+modelz[mo]+'.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rarefaction calculation\n",
    "def rarefact(rank,abundance,num_samples):\n",
    "    R=max(rank); L=sum(abundance)\n",
    "    r_list=np.zeros(num_samples)\n",
    "    n_list=range(1,num_samples+1)\n",
    "    for n in n_list:\n",
    "        ss=[]\n",
    "        for j in range(len(abundance)):\n",
    "            ss.append(sp.misc.comb(L-abundance[j],n))\n",
    "        r_list[n-1]=(R - sum(ss)/sp.misc.comb(L,n))    \n",
    "    return n_list,r_list\n",
    "\n",
    "#function that calculates approximation of rarefaction curve based on rank and abundance data (uses Stirling's)\n",
    "def rarefaction_approx(rank,abundance,num_samples):\n",
    "    R=max(rank); L=sum(abundance)\n",
    "    r_list=np.zeros(num_samples)\n",
    "    n_list=range(1,num_samples+1)\n",
    "    for n in n_list:\n",
    "        r_list[n-1]=R-np.sum((1-abundance/L)**n)\n",
    "    return n_list,r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.5,3),dpi=rez)\n",
    "for i in range(len(obz)):\n",
    "    #compute each experimental rarefaction curve\n",
    "    ranks=np.arange(len(obz[i].abundance))+1\n",
    "    data_nrare,data_Rrare = rarefact(ranks,obz[i].abundance,num_samples=int(obz[i].N))       \n",
    "    #data_nrare,data_Rrare = rarefaction_approx(ranks,obz[i].abundance,num_samples=int(obz[i].N))       \n",
    "    plt.plot(data_nrare,data_Rrare,color=obz[i].c,lw=2,alpha=0.7)\n",
    "#plt.xlabel('number of samples collected')\n",
    "#plt.ylabel('expected number of \\n distinct strains (observed)')\n",
    "plt.xlim([0,500])\n",
    "plt.ylim([0,500])\n",
    "plt.plot(np.linspace(1,1e3,5),np.linspace(1,1e3,5),ls='--',color='black')\n",
    "plt.tight_layout()\n",
    "plt.xlabel('sequence sample size, $N$')\n",
    "plt.ylabel('observed number \\n of distinct sequences')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/rarefaction_obs.pdf')   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot extrapolated rarefaction\n",
    "nums=2000\n",
    "for mo in range(3):\n",
    "    plt.figure(figsize=(3,3),dpi=rez)\n",
    "\n",
    "    for i in range(len(obz)):\n",
    "        abund=aex_list[mo][i]\n",
    "        \n",
    "        ranks=np.arange(1,len(abund)+1)\n",
    "        \n",
    "        sim_nrare,sim_Rrare=rarefaction_approx(ranks,abund,nums)\n",
    "        plt.plot(sim_nrare,sim_Rrare,color=obz[i].c)\n",
    "\n",
    "    #plt.title(modelz[mo],fontsize=10)\n",
    "    plt.xlabel('sequence sample size, $N^{ex}$')\n",
    "    plt.ylabel('extrapolated number \\n of distinct sequences')\n",
    "    plt.plot(np.linspace(1,nums,5),np.linspace(1,nums,5),ls='--',color='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/rarefaction_ex'+modelz[mo]+'.pdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
